# Music Generation

### Generate Music with Machine Learning.


> deep-learning sequence-modeling attention attention-mechanism nlp transformer keras


The songs are represented in sheet music (ABC) notation. The model ([Transformer](https://arxiv.org/abs/1706.03762)) takes metadata as input, creates an encoding from it, and uses the idea of attention to predict each note based on parts of this encoding. This paradigm is better at modeling higher-level structure than traditional sequence models, which suits the task of music generation.

- Attention is key. It makes sure that at each point of the output sequence, the token is generated only from parts of the input that are relevant.

- Processing the input in parallel rather than sequentially, gets rid of the problem of diminishing gradients, rather than mitigating it, in the case of LSTMs and GRUs. 

- Also, in sequence models, each point in the sequence is a bottleneck to all previous representations learned. This leads to poor performance on longer sequences.

- Positional encoding enables the model to tell where a token lies in the sequence, as input is processed in parallel.

---
### Model Architecture
![The Transformer Architecture](https://miro.medium.com/max/1252/1*JuGZaZcRtmrtCEPY8qfsUw.png)

---
### Preprocessing
Subword tokenization as opposed to character or word tokenization reduces the size of the vocabulary to be learned.

---
### Training
With a dataset size of 1000, a vocabulary size of 1000, an embedding size of 128, 4 encoder/decoder layers (Nx), 8 heads, and a batch size of 32, the model can take about 2000 iterations to converge, depending on the complexity of the dataset.

![Training](./plots/TrainingProgress.png)

---
### Pretrained Weights
[Here are pretrained weights.](./models/weights.h5)

---
### Outputs
Below are some of the songs generated by the model.

- [First song](./best/song1.wav)
- [Second song](./best/song2.wav)
- [Third song](./best/song3.wav)
- [Fourth song](./best/song4.wav)
- [Fifth song](./best/song5.wav)

---
### Run the Model

This model has been deployed [to a mobile application](https://play.google.com/store/apps/details?id=com.apptasticmobile.composeium). Feel free to use it if you do not have the python environment needed to run the source code.